{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, ChebConv, SAGEConv\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, GraphConv \n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from Lib import *\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, hidden_channels, num_node_features, num_classes, seed):\n",
    "        super(GCN, self).__init__()\n",
    "        torch.manual_seed(seed)\n",
    "        self.conv1 = GraphConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.conv3 = GraphConv(hidden_channels, hidden_channels)\n",
    "        self.lin = Linear(hidden_channels, num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        # 1. Obtain node embeddings \n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = x.relu()\n",
    "        x = self.conv3(x, edge_index)\n",
    "        # 2. Readout layer\n",
    "        x = global_mean_pool(x, batch)  # [batch_size, hidden_channels]\n",
    "        # 3. Apply a final classifier\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = self.lin(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def run(name_label, epochs, print_it, config):\n",
    "    dataset= load_data(name_label)\n",
    "    print(len(dataset))\n",
    "    memory_train=[]\n",
    "    memory_test=[]\n",
    "    model = GCN(hidden_channels=64,\\\n",
    "        num_node_features= dataset.num_features,\\\n",
    "        num_classes=dataset.num_classes).to(config['device'])\n",
    "    print(model)\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "    #import torch.optim.lr_scheduler as lrs\n",
    "    #scheduler = lrs.ExponentialLR(optimizer, gamma=0.9)\n",
    "    accuracies_mem = []\n",
    "    accuracies_one=[]\n",
    "    Total_loss=[]\n",
    "    Gen_loss=[]\n",
    "    For_loss=[]\n",
    "    n_Tasks=dataset.num_classes\n",
    "    for i in range(n_Tasks):\n",
    "        print(\"The task number\", i)\n",
    "        train_loader, test_loader, mem_train_loader, mem_test_loader,\\\n",
    "            memory_train, memory_test = continuum_Graph_classification(dataset, memory_train, memory_test, batch_size=64, task_id=i)\n",
    "        for epoch in range(1,epochs):\n",
    "            Total,Gen,For=train_CL(model, criterion, optimizer, mem_train_loader, train_loader, task=i, graph=1, node=0, params=config)\n",
    "            Total_loss.append(Total)\n",
    "            Gen_loss.append(Gen)\n",
    "            For_loss.append(For)\n",
    "            # print(epoch, print_it)\n",
    "            if epoch%print_it==0:\n",
    "                # scheduler.step()\n",
    "                train_acc = test_GC(model, train_loader)\n",
    "                test_acc = test_GC(model, test_loader)\n",
    "                mem_train_acc = test_GC(model, mem_train_loader)\n",
    "                mem_test_acc = test_GC(model, mem_test_loader)\n",
    "                accuracies_mem.append(mem_test_acc)\n",
    "                accuracies_one.append(test_acc)\n",
    "        print(\"#########################################################################\")\n",
    "        print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "        print(f'Mem Train Acc: {mem_train_acc:.4f}, Mem Test Acc: {mem_test_acc:.4f}')\n",
    "        print(\"#########################################################################\")\n",
    "\n",
    "    del model, criterion, optimizer, memory_train, memory_test, Total_loss, Gen_loss, For_loss\n",
    "    print(np.array(accuracies_one).reshape([-1]).shape, np.array(accuracies_mem).reshape([-1]).shape)\n",
    "    return np.array(accuracies_one).reshape([-1]), np.array(accuracies_mem).reshape([-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " import torch \n",
    " torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = {'x_updates': 1,  'theta_updates':1, 'factor': 1, 'x_lr': 0.0001,'th_lr':0.0001,\\\n",
    "            'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\\\n",
    "            'batchsize':8, 'total_updates': 1000} \n",
    "\n",
    "\n",
    "import numpy as np\n",
    "total_epoch=5000\n",
    "print_it=50\n",
    "total_runs=5\n",
    "n_Tasks=2\n",
    "acc_one = np.zeros((total_runs,((total_epoch//print_it-1)*n_Tasks)))\n",
    "acc_m = np.zeros((total_runs,((total_epoch//print_it-1)*n_Tasks)))\n",
    "name_label='MUTAG'\n",
    "save_dir='MUTAG/'\n",
    "for i in range(total_runs):\n",
    "    acc_one[i,:], acc_m[i,:] =run(name_label, epochs=total_epoch, print_it=print_it, config=configuration)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "accuracies_mem=np.mean(acc_m, axis=0)\n",
    "accuracies_one=np.mean(acc_one, axis=0)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(accuracies_mem, label='memory accuracy')\n",
    "plt.plot(accuracies_one, label='task accuracy')\n",
    "np.savetxt(save_dir+name_label+'_acc_runs_5.csv', np.concatenate([accuracies_one, accuracies_mem],\\\n",
    "                                                                 axis=1), delimeter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_save(acc_m, acc_one, save_dir, name_label, total_epoch, print_it, total_runs, n_Tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43239fae0033db1a2e66a9531b910ee36f1ddb94ee4e094adae59038a1ee66a8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
