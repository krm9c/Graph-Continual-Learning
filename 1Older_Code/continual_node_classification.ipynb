{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class GAT(torch.nn.Module):\n",
    "    def __init__(self, nfeat, nclass):\n",
    "        super(GAT, self).__init__()\n",
    "        self.hid = 8\n",
    "        self.in_head = 8\n",
    "        self.out_head = 1\n",
    "        \n",
    "        self.conv1 = GATConv(nfeat, self.hid, heads=self.in_head, dropout=0.6)\n",
    "        self.conv2 = GATConv(self.hid*self.in_head, nclass, concat=False,\n",
    "                             heads=self.out_head, dropout=0.6)\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = F.dropout(x, p=0.6, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from the load dataset tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Dataset: Cora():\n",
      "======================\n",
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "Data(x=[2708, 1433], edge_index=[2, 10556], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])\n",
      "Number of Classes in Cora: 7\n",
      "Number of Node Features in Cora: 1433\n",
      "features inside the start tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "lable, n_task 7 1\n",
      "13 20\n",
      "69 130\n",
      "13 20\n",
      "69 130\n",
      "#########################################################################\n",
      "Epoch: 000, Train Acc: 0.6500, Test Acc: 0.5308\n",
      "Mem Train Acc: 0.6500, Mem Test Acc: 0.5308\n",
      "#########################################################################\n",
      "20 20\n",
      "130 130\n",
      "20 20\n",
      "130 130\n",
      "#########################################################################\n",
      "Epoch: 050, Train Acc: 1.0000, Test Acc: 1.0000\n",
      "Mem Train Acc: 1.0000, Mem Test Acc: 1.0000\n",
      "#########################################################################\n",
      "0 20\n",
      "0 91\n",
      "20 20\n",
      "0 20\n",
      "130 130\n",
      "0 91\n",
      "#########################################################################\n",
      "Epoch: 000, Train Acc: 0.0000, Test Acc: 0.0000\n",
      "Mem Train Acc: 0.5000, Mem Test Acc: 0.5000\n",
      "#########################################################################\n",
      "20 20\n",
      "87 91\n",
      "20 20\n",
      "20 20\n",
      "115 130\n",
      "87 91\n",
      "#########################################################################\n",
      "Epoch: 050, Train Acc: 1.0000, Test Acc: 0.9560\n",
      "Mem Train Acc: 1.0000, Mem Test Acc: 0.9203\n",
      "#########################################################################\n"
     ]
    }
   ],
   "source": [
    "from Lib import *\n",
    "\n",
    "def run(name_data, epochs, print_it, config):\n",
    "    # The data characteristics\n",
    "    dataset= load_data(name_data)\n",
    "    print(dataset[0])\n",
    "    print(f\"Number of Classes in {name_data}:\", dataset.num_classes)\n",
    "    print(f\"Number of Node Features in {name_data}:\", dataset.num_node_features)\n",
    "    n_Tasks=dataset.num_classes\n",
    "    x = dataset[0].x\n",
    "    y = dataset[0].y\n",
    "    edge_index = dataset[0].edge_index \n",
    "    continuum_data = continuum_node_classification(dataset, n_Tasks, num_classes=dataset.num_classes)\n",
    "\n",
    "    # The model use GCN\n",
    "    # model = GCN(hidden_channels=16, num_features=dataset.num_features, n_classes=dataset.num_classes)\n",
    "    # The Gat model\n",
    "\n",
    "    model = GAT(nfeat=dataset.num_node_features, \n",
    "                nclass=dataset.num_classes)\n",
    "\n",
    "\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "    # The arrays for data\n",
    "    memory_train=[]\n",
    "    memory_test=[]\n",
    "    memory_valid=[]\n",
    "    accuracies_mem = []\n",
    "    accuracies_one=[]\n",
    "    Total_loss=[]\n",
    "    Gen_loss=[]\n",
    "    For_loss=[]\n",
    "\n",
    "    for id, task in enumerate(continuum_data):\n",
    "        train_mask, _, test_mask = task\n",
    "        memory_train.append(train_mask)\n",
    "        memory_test.append(test_mask)\n",
    "        for epoch in range(epochs):\n",
    "            # loss = train(model, Data(x=x,edge_index=edge_index, y=y, train_mask=train_mask),\\\n",
    "            #       optimizer, criterion)\n",
    "            # print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')\n",
    "            train_loader= Data(x=x,edge_index=edge_index, y=y, train_mask=train_mask)\n",
    "            Total,Gen,For=train_CL( model, criterion, optimizer, memory_train, train_loader, task=id, \\\n",
    "                graph = 0, node=1, params = config)\n",
    "            Total_loss.append(Total)\n",
    "            Gen_loss.append(Gen)\n",
    "            For_loss.append(For)\n",
    "\n",
    "            if epoch%print_it==0:\n",
    "                # scheduler.step()\n",
    "                train_acc = test_NC(model, train_loader.x, train_loader.edge_index, train_mask, train_loader.y)\n",
    "                test_acc = test_NC(model,  train_loader.x, train_loader.edge_index, test_mask, train_loader.y)\n",
    "                mem_train_acc= [ test_NC(model, train_loader.x, train_loader.edge_index, element, train_loader.y) for element in memory_train]\n",
    "                mem_train_acc = sum(mem_train_acc)/len(memory_train)\n",
    "                mem_test_acc= [ test_NC(model, train_loader.x, train_loader.edge_index, element, train_loader.y) for element in memory_test]\n",
    "                mem_test_acc  = sum(mem_test_acc)/len(memory_test)\n",
    "                accuracies_mem.append(mem_test_acc)\n",
    "                accuracies_one.append(test_acc)\n",
    "                print(\"#########################################################################\")\n",
    "                print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n",
    "                print(f'Mem Train Acc: {mem_train_acc:.4f}, Mem Test Acc: {mem_test_acc:.4f}')\n",
    "                print(\"#########################################################################\")\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(accuracies_mem, label='memory accuracy')\n",
    "    plt.plot(accuracies_one, label='task accuracy')\n",
    "    return accuracies_mem, accuracies_one\n",
    "\n",
    "run('Cora', epochs=100, print_it=50, config={'x_updates': 10,  'theta_updates': 10, 'factor': 1, 'x_lr': 0.001,'th_lr':0.001,\\\n",
    "                'device': torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\\\n",
    "                'batchsize':8, 'total_updates': 1000} )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "43239fae0033db1a2e66a9531b910ee36f1ddb94ee4e094adae59038a1ee66a8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('dh_posei')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
